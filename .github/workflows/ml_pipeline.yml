name: ML Pipeline

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

jobs:
  build-and-test:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.8'
    
    - name: Cache pip packages
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        # Install CPU-only PyTorch
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
        # Install other dependencies
        pip install numpy matplotlib pytest pytest-md
        # Install visualization tools
        sudo apt-get update
        sudo apt-get install -y graphviz tree
        pip install graphviz torchviz
    
    - name: Create directories
      run: |
        mkdir -p models
        mkdir -p visualizations
        mkdir -p visualizations/augmentations
    
    - name: Generate augmentation visualizations
      env:
        SKIP_VIZ: 0
        PYTHONPATH: ${GITHUB_WORKSPACE}
      run: |
        echo "Generating augmentation visualizations..."
        
        # Ensure directories exist
        mkdir -p visualizations/augmentations
        
        # Generate augmentations with debug output
        python -c "
        import os
        import matplotlib
        matplotlib.use('Agg')
        from tests.test_model import generate_augmentation_samples
        
        print('Current working directory:', os.getcwd())
        print('Contents before generation:', os.listdir('visualizations/augmentations'))
        
        generate_augmentation_samples()
        
        print('\nContents after generation:', os.listdir('visualizations/augmentations'))
        for root, dirs, files in os.walk('visualizations/augmentations'):
            print(f'\nDirectory: {root}')
            print('Files:', files)
        "
        
        # Display generated files
        echo "\nGenerated files structure:"
        find visualizations/augmentations -type f -ls
        
        # Create summary of generated files
        echo "\nCreating augmentation summary..."
        echo "# Generated Augmentation Files" > augmentation_files.md
        find visualizations/augmentations -type f | sort >> augmentation_files.md

    - name: Upload augmentation artifacts
      uses: actions/upload-artifact@v3
      with:
        name: augmentation-images
        path: |
          visualizations/augmentations/**/*
          augmentation_files.md

    - name: Train model
      env:
        CUDA_VISIBLE_DEVICES: ""
        TORCH_DEVICE: "cpu"
        SKIP_VIZ: 1  # Skip visualization during training
      run: |
        echo "Starting model training..."
        python train.py
        echo "Training completed."
        echo "TRAINED_MODEL_PATH=$(ls -t models/*.pth | head -1)" >> $GITHUB_ENV
    
    - name: Run tests
      env:
        CUDA_VISIBLE_DEVICES: ""
        TORCH_DEVICE: "cpu"
        SKIP_VIZ: 1
      run: |
        echo "Running model tests..."
        echo "Using model: $TRAINED_MODEL_PATH"
        pytest tests/test_model.py -v -s
        echo "Testing completed."
    
    - name: Generate test summary
      run: |
        echo "## ML Pipeline Results" >> $GITHUB_STEP_SUMMARY
        
        echo "### Data Augmentations" >> $GITHUB_STEP_SUMMARY
        if [ -f "augmentation_files.md" ]; then
          cat augmentation_files.md >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "visualizations/augmentations/README.md" ]; then
          echo "\n### Augmentation Details" >> $GITHUB_STEP_SUMMARY
          cat visualizations/augmentations/README.md >> $GITHUB_STEP_SUMMARY
        fi
        
        if [ -f "test-summary.md" ]; then
          echo "\n### Test Results" >> $GITHUB_STEP_SUMMARY
          cat test-summary.md >> $GITHUB_STEP_SUMMARY
        fi
    
    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v3
      with:
        name: ml-pipeline-artifacts
        path: |
          models/
          visualizations/augmentations/
          visualizations/augmentations/**/*
          test-summary.md
    
    - name: Verify requirements
      run: |
        echo "Checking model requirements..."
        
        # Check parameter count
        if [ -f "visualizations/model_architecture.txt" ]; then
          PARAM_COUNT=$(grep "Total Parameters:" visualizations/model_architecture.txt | awk '{print $3}' | tr -d ',')
          if [ "$PARAM_COUNT" -gt 25000 ]; then
            echo "❌ Parameter count ($PARAM_COUNT) exceeds limit of 25,000"
            exit 1
          else
            echo "✅ Parameter count ($PARAM_COUNT) within limit"
          fi
        fi
        
        # Check accuracy
        if [ -f "test-summary.md" ]; then
          if grep -q "FAILED" test-summary.md; then
            echo "❌ Model tests failed!"
            exit 1
          else
            echo "✅ All model tests passed"
          fi
        else
          echo "❌ Test summary not found"
          exit 1
        fi

    - name: Cleanup
      if: always()
      run: |
        rm -rf .pytest_cache
        rm -rf __pycache__